{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDateInColumns(df):\n",
    "    for index, row in df.iterrows():\n",
    "        date_object = row[\"Date\"]\n",
    "        df.at[index, 'Day'] = date_object.day\n",
    "        df.at[index, 'Month'] = date_object.month\n",
    "        df.at[index, 'Year'] = date_object.year\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution from : https://stackoverflow.com/questions/32854677/how-to-deal-with-multiple-date-string-formats-in-a-python-series\n",
    "def timeToSeconds(timestr):\n",
    "    for fmt in (\"%M:%S.%f\", \"%S.%f\", \"%S:%f\", \"%M:%S:%f\"):\n",
    "        try:\n",
    "            t = datetime.strptime(timestr, fmt)\n",
    "            seconds = (t.minute * 60) + t.second + (t.microsecond * 1e-6)\n",
    "            return round(seconds)\n",
    "            break\n",
    "        except ValueError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTeams(df):\n",
    "    for index, row in df.iterrows():\n",
    "        person1 = row[\"Person 1\"].upper()\n",
    "        person2 = row[\"Person 2\"].upper()\n",
    "        team = (person1 + \"_\" + person2).replace(\" \",\"\")\n",
    "        team = team.replace(\",\",\"\")\n",
    "        df.at[index,\"Team\"]  = team\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanColumns(df):\n",
    "    #df.info()\n",
    "    df = df.dropna(subset=['Date', 'Person 1', 'Person 2','split time 1','split time 2','split time 3', 'Total Time'])\n",
    "\n",
    "    for index,row in df.iterrows():\n",
    "        df.at[index,\"Date\"] = row[\"Date\"] + \" \" + row[\"Time\"]\n",
    "\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "    df.set_index(\"Date\")\n",
    "    df = df.sort_index()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createIDs(df):\n",
    "    df['Competition_ID'] = df.groupby([\"Year\",\"Place\"]).grouper.label_info\n",
    "    df['Race_ID'] = df.groupby([\"Date\"]).grouper.label_info\n",
    "    df['Team_ID'] = df.groupby([\"Team\"]).grouper.label_info\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addTimeToDateIndex(df):\n",
    "    for index,row in df.iterrows():\n",
    "        timeObj = datetime.strptime(row[\"Time\"],'%H:%M')\n",
    "        df.at[index,\"Date\"] = datetime.datetime.combine(row[\"Date\"],timeObj)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertTimes(df):\n",
    "    for index, row in df.iterrows():\n",
    "        df.at[index, \"split time 1\"] = timeToSeconds(row[\"split time 1\"])\n",
    "        df.at[index, \"split time 2\"] = timeToSeconds(row[\"split time 2\"])\n",
    "        df.at[index, \"split time 3\"] = timeToSeconds(row[\"split time 3\"])\n",
    "        df.at[index, \"Total Time\"] = timeToSeconds(row[\"Total Time\"])\n",
    "    return df\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCompetitionColumns(df):\n",
    "    df = pd.get_dummies(df,columns=['Competiton Type','Competition Round'], dtype=bool)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_DeltaTimes(df):\n",
    "   for index, row in df.iterrows():\n",
    "      df.at[index,\"D0_250\"] = row[\"split time 1\"]\n",
    "      df.at[index,\"D250_500\"] = pd.to_numeric(row[\"split time 2\"])-pd.to_numeric(row[\"split time 1\"])\n",
    "      df.at[index,\"D500_750\"] = pd.to_numeric(row[\"split time 3\"])-pd.to_numeric(row[\"split time 2\"])\n",
    "      df.at[index,\"D750_1000\"] = pd.to_numeric(row[\"Total Time\"])-pd.to_numeric(row[\"split time 3\"])\n",
    "   return df\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPb_TimecurrentSeason(df):\n",
    "    for index, row in df.iterrows():\n",
    "        #Verkrijg alle resultaten voor deze datum en van hetzelfde jaar \n",
    "        results = df[(df[\"Year\"] == row[\"Year\"]) & (df[\"Date\"] < row[\"Date\"]) & (df[\"Team\"]==row[\"Team\"])].sort_values(\"Total Time\")\n",
    "        if(results.shape[0] > 0):\n",
    "            bestTime = results[\"Total Time\"].iloc[0]\n",
    "            df.at[index,\"BestSeasonTime\"] = bestTime\n",
    "        else: \n",
    "            bestTime = row[\"Total Time\"]\n",
    "            df.at[index,\"BestSeasonTime\"] = bestTime\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shows how many races a team has paddled together before current race\n",
    "def createCompetitionTotal(df):\n",
    "    for index, row in df.iterrows():\n",
    "        #Get all the results of a Team before current Race\n",
    "        results = df[(df[\"Date\"] < row[\"Date\"]) & (df[\"Team\"]==row[\"Team\"])]\n",
    "        #Count 1 Competition with multiple races as 1\n",
    "        uniqueCount = results.groupby(['Year','Place']).ngroups\n",
    "        df.at[index,\"TotalRacesTogether\"] = uniqueCount\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the count of A finals before the current Race\n",
    "def getTotalAFinalsTeam(df):\n",
    "    for index, row in df.iterrows():\n",
    "        #Get all The races before this race of one team where the competition round was an A Final\n",
    "        results = df[(df[\"Date\"] < row[\"Date\"]) & (df[\"Team\"]==row[\"Team\"]) & (df[\"Competition Round_FINAL A\"] == True) ]\n",
    "        #Count 1 Competition with multiple races as 1\n",
    "        uniqueCount = results.groupby(['Year','Place']).ngroups\n",
    "        df.at[index,\"TotalAFinalsTogether\"] = uniqueCount\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the count of Semi finals before the current Race\n",
    "def getTotalSemiFinalsTeam(df):\n",
    "    for index, row in df.iterrows():\n",
    "        #Get all The races before this race of one team where the competition round was an Semi Final\n",
    "        results = df[(df[\"Date\"] < row[\"Date\"]) & (df[\"Team\"]==row[\"Team\"]) & (df[\"Competition Round_SEMIFINAL\"] == True) ]\n",
    "        #Count 1 Competition with multiple races as 1\n",
    "        uniqueCount = results.groupby(['Year','Place']).ngroups\n",
    "        df.at[index,\"TotalSemiFinalsTogether\"] = uniqueCount\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Reached_FinalA(df):\n",
    "    #Loop over elke row\n",
    "    for index, row in df.iterrows():\n",
    "        #check of ploeg in row i in de a finale komt\n",
    "        dataCount = df[(df[\"Competition Round_FINAL A\"] == True) & (df[\"Year\"] == row[\"Year\"]) & (df[\"Place\"] == row[\"Place\"]) & (df[\"Team\"] == row[\"Team\"])].shape[0]\n",
    "        #als ploeg in de a finale geraakt\n",
    "        if(dataCount >= 1):\n",
    "            df.at[index,\"Reached_FINAL_A\"] = True\n",
    "        else: \n",
    "            df.at[index,\"Reached_FINAL_A\"] = False        \n",
    "    return df\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Reached_Semi(df):\n",
    "    #Loop over elke row\n",
    "    for index, row in df.iterrows():\n",
    "        #check of ploeg in row i in de Semi komt\n",
    "        dataCount = df.loc[(df[\"Competition Round_SEMIFINAL\"] == True) & (df[\"Year\"] == row[\"Year\"]) & (df[\"Place\"] == row[\"Place\"]) & (df[\"Team\"] == row[\"Team\"])].shape[0]\n",
    "        #als ploeg in de a finale geraakt\n",
    "        if(dataCount >= 1):\n",
    "            df.at[index,\"Reached_SEMI\"] = True\n",
    "        else: \n",
    "            df.at[index,\"Reached_SEMI\"] = False        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_count_FinalA_currentSeason(df):\n",
    "    for index, row in df.iterrows():\n",
    "        #Verkrijg alle resultaten voor deze datum en van hetzelfde jaar \n",
    "        results = df[(df[\"Year\"] == row[\"Year\"]) & (df[\"Date\"] < row[\"Date\"]) & (df[\"Team\"]==row[\"Team\"]) & (df[\"Competition Round_FINAL A\"] == True)].shape[0]\n",
    "        df.at[index,\"FinalA_count_Season\"] = results\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def rankeRaces(df):\n",
    "    Results = pd.DataFrame(columns=[\"Race_ID\",\"TT1\",\"TT2\",\"TT3\",\"TT4\",\"TT5\",\"TT6\",\"TT7\",\"TT8\",\"TT9\"])\n",
    "    racesGrouped = df.groupby(\"Race_ID\")\n",
    "\n",
    "    for name, group in racesGrouped:\n",
    "        race = group.reset_index()\n",
    "        race = race.sort_values(by=\"Total Time\")[\"Total Time\"].to_numpy()\n",
    "        race = np.append(race,np.full(9-race.size,-1))\n",
    "\n",
    "        Results = Results.append({\"Race_ID\":name,\"TT1\":race[0],\"TT2\":race[1],\"TT3\":race[2],\"TT4\":race[3],\"TT5\":race[4],\"TT6\":race[5],\"TT7\":race[6],\"TT8\":race[7],\"TT9\":race[8]},ignore_index=True)\n",
    "    \n",
    "    df = pd.merge(df,Results,on=\"Race_ID\")\n",
    "    return df\n",
    "\n",
    "def rankeRaces250(df):\n",
    "    Results = pd.DataFrame(columns=[\"Race_ID\",\"T1_250\",\"T2_250\",\"T3_250\",\"T4_250\",\"T5_250\",\"T6_250\",\"T7_250\",\"T8_250\",\"T9_250\"])\n",
    "    racesGrouped = df.groupby(\"Race_ID\")\n",
    "\n",
    "    for name, group in racesGrouped:\n",
    "        race = group.reset_index()\n",
    "        race = race.sort_values(by=\"split time 1\")[\"split time 1\"].to_numpy()\n",
    "        race = np.append(race,np.full(9-race.size,-1))\n",
    "\n",
    "        Results = Results.append({\"Race_ID\":name,\"T1_250\":race[0],\"T2_250\":race[1],\"T3_250\":race[2],\"T4_250\":race[3],\"T5_250\":race[4],\"T6_250\":race[5],\"T7_250\":race[6],\"T8_250\":race[7],\"T9_250\":race[8]},ignore_index=True)\n",
    "    \n",
    "    df = pd.merge(df,Results,on=\"Race_ID\")\n",
    "    return df\n",
    "\n",
    "def rankeRaces500(df):\n",
    "    Results = pd.DataFrame(columns=[\"Race_ID\",\"T1_500\",\"T2_500\",\"T3_500\",\"T4_500\",\"T5_500\",\"T6_500\",\"T7_500\",\"T8_500\",\"T9_500\"])\n",
    "    racesGrouped = df.groupby(\"Race_ID\")\n",
    "\n",
    "    for name, group in racesGrouped:\n",
    "        race = group.reset_index()\n",
    "        race = race.sort_values(by=\"split time 1\")[\"split time 2\"].to_numpy()\n",
    "        race = np.append(race,np.full(9-race.size,-1))\n",
    "\n",
    "        Results = Results.append({\"Race_ID\":name,\"T1_500\":race[0],\"T2_500\":race[1],\"T3_500\":race[2],\"T4_500\":race[3],\"T5_500\":race[4],\"T6_500\":race[5],\"T7_500\":race[6],\"T8_500\":race[7],\"T9_500\":race[8]},ignore_index=True)\n",
    "    \n",
    "    df = pd.merge(df,Results,on=\"Race_ID\")\n",
    "    return df\n",
    "\n",
    "def rankeRaces750(df):\n",
    "    Results = pd.DataFrame(columns=[\"Race_ID\",\"T1_750\",\"T2_750\",\"T3_750\",\"T4_750\",\"T5_750\",\"T6_750\",\"T7_750\",\"T8_750\",\"T9_750\"])\n",
    "    racesGrouped = df.groupby(\"Race_ID\")\n",
    "\n",
    "    for name, group in racesGrouped:\n",
    "        race = group.reset_index()\n",
    "        race = race.sort_values(by=\"split time 1\")[\"split time 3\"].to_numpy()\n",
    "        race = np.append(race,np.full(9-race.size,-1))\n",
    "\n",
    "        Results = Results.append({\"Race_ID\":name,\"T1_750\":race[0],\"T2_750\":race[1],\"T3_750\":race[2],\"T4_750\":race[3],\"T5_750\":race[4],\"T6_750\":race[5],\"T7_750\":race[6],\"T8_750\":race[7],\"T9_750\":race[8]},ignore_index=True)\n",
    "    \n",
    "    df = pd.merge(df,Results,on=\"Race_ID\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verkrijg de gemiddelde tijd die er in een race is gevaren\n",
    "def getAverageTimeofRace(df):\n",
    "    dfc = df.groupby(\"Date\")[\"Total Time\"].mean().to_frame(\"avgTotalTime\").reset_index()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropColumns(df):\n",
    "    df = df.drop(columns=[\"Person 1\", \"Person 2\",\"Wind Speed\", \"Wind Direction\",\"Sex\",\"Category\"],axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bereken de gemiddelde Totaal Tijd van de eerste 3 boten in een race\n",
    "def createAVGTIMETOP3(df):\n",
    "    #behoud enkel de boten die in de top 3 zijn geraakt per race\n",
    "    filterTop3= df[(df[\"Final Rank\"] < 4)]\n",
    "    #Tijd naar nummer converteren\n",
    "    filterTop3[\"Total Time\"] = pd.to_numeric(filterTop3[\"Total Time\"])\n",
    "    #Groepeer per race en neem het gemiddelde van deze groep(race)\n",
    "    groupbyRace = filterTop3.groupby(\"Date\")[\"Total Time\"].mean().to_frame(name=\"Top3Avg\").reset_index()\n",
    "    #Merge  gemiddelden met dataset\n",
    "    df = pd.merge(df,groupbyRace,how=\"outer\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creeer de snelste tijd in de Heats per Competitie\n",
    "def createFastestHeatTimeInCompetition(df):\n",
    "    #behoud enkel de heats\n",
    "    filterHeat = df[(df[\"Competition Round_HEAT\"] == True)]\n",
    "    #groepeer per Competitie(Plaat,Jaar) en neem de kleinste totaal tijd\n",
    "    raceGroups = filterHeat.groupby([\"Place\",\"Year\"])[\"Total Time\"].min().to_frame(name=\"N1THeatCompetition\").reset_index()\n",
    "    #Merge de data set\n",
    "    df = pd.merge(df,raceGroups,on=[\"Place\",\"Year\"])\n",
    "    return df\n",
    "\n",
    "#Creeer de snelste tijd in de Semi Finals per Competitie\n",
    "def createFastestSemiTimeInCompetition(df):\n",
    "    #behoud enkel de semis\n",
    "    filterSemi = df[(df[\"Competition Round_SEMIFINAL\"] == True)]\n",
    "    #groepeer per Competitie(Plaat,Jaar) en neem de kleinste totaal tijd\n",
    "    raceGroups = filterSemi.groupby([\"Place\",\"Year\"])[\"Total Time\"].min().to_frame(name=\"N1TSemiCompetition\").reset_index()\n",
    "    #Merge de data set\n",
    "    df = pd.merge(df,raceGroups,on=[\"Place\",\"Year\"])\n",
    "    return df\n",
    "\n",
    "#Creeer de snelste tijd in de A finale per Competitie\n",
    "def createFastestFinalTimeInCompetition(df):\n",
    "    #behoud enkel de A Finales\n",
    "    filterFinal = df[(df[\"Competition Round_FINAL A\"] == True)]\n",
    "    #groepeer per Competitie(Plaat,Jaar) en neem de kleinste totaal tijd\n",
    "    raceGroups = filterFinal.groupby([\"Place\",\"Year\"])[\"Total Time\"].min().to_frame(name=\"N1TFinalACompetition\").reset_index()\n",
    "    #Merge de data set\n",
    "    df = pd.merge(df,raceGroups,on=[\"Place\",\"Year\"])\n",
    "    return df\n",
    "    \n",
    "def createFastestTimeInCompetition(df):\n",
    "    raceGroups = df.groupby(\"Competition_ID\")[\"Total Time\"].min().to_frame(name=\"N1TCompetition\").reset_index()\n",
    "    #Merge de data set\n",
    "    df = pd.merge(df,raceGroups,on=\"Competition_ID\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creeer het gemiddelde van de snelste 3 tijden in de heats per Competitie\n",
    "def createAvgTop3HeatTimeInCompetition(df):\n",
    "    Averages = pd.DataFrame(columns=[\"Competition_ID\",\"HeatTop3Avg\"])\n",
    "    df[\"Total Time\"] = pd.to_numeric(df[\"Total Time\"])\n",
    "    HeatTimes = df[(df[\"Competition Round_HEAT\"] == True)].copy()\n",
    "    competitionGroups = HeatTimes.groupby(\"Competition_ID\")\n",
    "    for name, group in competitionGroups:\n",
    "        Averages = Averages.append({\"Competition_ID\":str(name),\"HeatTop3Avg\":group.nsmallest(3,\"Total Time\")[\"Total Time\"].mean()},ignore_index=True)\n",
    "\n",
    "    Averages[\"Competition_ID\"] = Averages[\"Competition_ID\"].astype('int64')\n",
    "    df = pd.merge(df,Averages,on=\"Competition_ID\")\n",
    "    return df\n",
    "\n",
    "# Creeer het gemiddelde van de snelste 3 tijden in de SemiFinals per Competitie\n",
    "def createAvgTop3SemiTimeInCompetition(df):\n",
    "    Averages2 = pd.DataFrame(columns=[\"Competition_ID\",\"SemiTop3Avg\"])\n",
    "    df[\"Total Time\"] = pd.to_numeric(df[\"Total Time\"])\n",
    "    SemiTimes = df[(df[\"Competition Round_SEMIFINAL\"] == True)].copy()\n",
    "    competitionGroups2 = SemiTimes.groupby(\"Competition_ID\")\n",
    "    for name, group in competitionGroups2:\n",
    "        Averages2 = Averages2.append({\"Competition_ID\":str(name),\"SemiTop3Avg\":group.nsmallest(3,\"Total Time\")[\"Total Time\"].mean()},ignore_index=True)\n",
    "\n",
    "    Averages2[\"Competition_ID\"] = Averages2[\"Competition_ID\"].astype('int64')\n",
    "    df = pd.merge(df,Averages2,on=\"Competition_ID\")\n",
    "    return df\n",
    "\n",
    "# Creeer het gemiddelde van de snelste 9 tijden in de SemiFinals per Competitie\n",
    "def createAvgTop9SemiTimeInCompetition(df):\n",
    "    Averages = pd.DataFrame(columns=[\"Competition_ID\",\"SemiTop9Avg\"])\n",
    "    df[\"Total Time\"] = pd.to_numeric(df[\"Total Time\"])\n",
    "    SemiTimes = df[(df[\"Competition Round_SEMIFINAL\"] == True)].copy()\n",
    "    competitionGroups = SemiTimes.groupby(\"Competition_ID\")\n",
    "    for name, group in competitionGroups:\n",
    "        Averages = Averages.append({\"Competition_ID\":str(name),\"SemiTop9Avg\":group.nsmallest(9,\"Total Time\")[\"Total Time\"].mean()},ignore_index=True)\n",
    "\n",
    "    Averages[\"Competition_ID\"] = Averages[\"Competition_ID\"].astype('int64')\n",
    "    df = pd.merge(df,Averages,on=\"Competition_ID\")\n",
    "    return df\n",
    "\n",
    "# Creeer het gemiddelde van de snelste 3 tijden in de heats per Competitie\n",
    "def createAvgTop9HeatTimeInCompetition(df):\n",
    "    Averages = pd.DataFrame(columns=[\"Competition_ID\",\"HeatTop9Avg\"])\n",
    "    df[\"Total Time\"] = pd.to_numeric(df[\"Total Time\"])\n",
    "    HeatTimes = df[(df[\"Competition Round_HEAT\"] == True)].copy()\n",
    "    competitionGroups = HeatTimes.groupby(\"Competition_ID\")\n",
    "    for name, group in competitionGroups:\n",
    "        Averages = Averages.append({\"Competition_ID\":str(name),\"HeatTop9Avg\":group.nsmallest(9,\"Total Time\")[\"Total Time\"].mean()},ignore_index=True)\n",
    "\n",
    "    Averages[\"Competition_ID\"] = Averages[\"Competition_ID\"].astype('int64')\n",
    "    df = pd.merge(df,Averages,on=\"Competition_ID\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying to gues the weather conditions in a Race \n",
    "    #-1:Fast Conditions\n",
    "    #0: Neutral Conditions\n",
    "    #1: Slow Condtions\n",
    "def createConditions(df):\n",
    "    #Take only the first 3 boats in each race\n",
    "    data = df[(df[\"Final Rank\"] < 4)]\n",
    "    #Group them by Place and take q1,q2,q3 of the total times\n",
    "    q1groupes = data.groupby(\"Place\")[\"Total Time\"].quantile(0.25).to_frame(name=\"q1\")\n",
    "    q2groupes = data.groupby(\"Place\")[\"Total Time\"].quantile().to_frame(name=\"q2\")\n",
    "    q3groupes = data.groupby(\"Place\")[\"Total Time\"].quantile(0.75).to_frame(name=\"q3\")\n",
    "    mergedq1q2 = pd.merge(q1groupes,q2groupes,on=\"Place\")\n",
    "    merge = pd.merge(mergedq1q2,q3groupes,on=\"Place\").reset_index()\n",
    "\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        #get calculated quantile values for each place\n",
    "        q1 = merge.loc[merge[\"Place\"] == row[\"Place\"]][\"q1\"].values[0]\n",
    "        q2 = merge.loc[merge[\"Place\"] == row[\"Place\"]][\"q2\"].values[0]\n",
    "        q3 = merge.loc[merge[\"Place\"] == row[\"Place\"]][\"q3\"].values[0]\n",
    "\n",
    "        #if the Top3avg of a race is faster then q1 of that place -> fast condition\n",
    "        if(row[\"Top3Avg\"] < q1) : df.at[index,\"Condition\"] = \"-1\"\n",
    "        #if the Top3avg of a race is slower then q3 of that place -> slow condition\n",
    "        elif(row[\"Top3Avg\"] > q3) : df.at[index,\"Condition\"] = \"1\"\n",
    "        #else -> neutral condition\n",
    "        else: df.at[index,\"Condition\"] = \"0\"\n",
    "    return df\n",
    "    \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMovingWindow(dataset):\n",
    "    grouped = dataset.groupby(\"Team\")\n",
    "    results = pd.DataFrame(columns=[\"Date\",\"Team\",\"Total Time\",\"Final Rank\"]).set_index('Date')\n",
    "    for name, group in grouped:\n",
    "        df = group[[\"Date\",\"Team\",\"Total Time\",\"Final Rank\"]].set_index(\"Date\").sort_values(by=[\"Date\"])\n",
    "        df[\"TotalTime-1\"] = df[\"Total Time\"].shift(1) \n",
    "        df[\"Rank-1\"] = df[\"Final Rank\"].shift(1)\n",
    "\n",
    "        df[\"TotalTime-2\"] = df[\"Total Time\"].shift(2) \n",
    "        df[\"Rank-2\"] = df[\"Final Rank\"].shift(2)\n",
    "\n",
    "        df[\"TotalTime-3\"] = df[\"Total Time\"].shift(3) \n",
    "        df[\"Rank-3\"] = df[\"Final Rank\"].shift(3)\n",
    "\n",
    "\n",
    "        df[\"TotalTime-4\"] = df[\"Total Time\"].shift(4) \n",
    "        df[\"Rank-4\"] = df[\"Final Rank\"].shift(4)\n",
    "\n",
    "        df[\"TotalTime-5\"] = df[\"Total Time\"].shift(5) \n",
    "        df[\"Rank-5\"] = df[\"Final Rank\"].shift(5)\n",
    "\n",
    "        results = pd.concat([results,df],sort=False)\n",
    "\n",
    "    df = pd.merge(dataset,results,on=\"Team\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "C:\\Users\\Bram Sikkens\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \nC:\\Users\\Bram Sikkens\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \nIndex(['Date', 'Place', 'Time', 'Category', 'Sex', 'Country', 'Lane',\n       'Person 1', 'Person 2', 'split time 1', 'split time 2', 'split time 3',\n       'Total Time_x', 'Final Rank_x', 'Air Temp', 'Wind Speed',\n       'Wind Direction', 'Day', 'Month', 'Year', 'Team', 'Competition_ID',\n       'Race_ID', 'Team_ID', 'Competiton Type_WORLDCHAMPIONSHIPS',\n       'Competiton Type_WORLDCUP', 'Competition Round_FINAL A',\n       'Competition Round_FINAL B', 'Competition Round_FINAL C',\n       'Competition Round_HEAT', 'Competition Round_SEMIFINAL',\n       'Reached_FINAL_A', 'Reached_SEMI', 'D0_250', 'D250_500', 'D500_750',\n       'D750_1000', 'FinalA_count_Season', 'BestSeasonTime', 'Top3Avg',\n       'TotalRacesTogether', 'TotalAFinalsTogether', 'TotalSemiFinalsTogether',\n       'N1THeatCompetition', 'N1TSemiCompetition', 'N1TFinalACompetition',\n       'N1TCompetition', 'HeatTop3Avg', 'SemiTop3Avg', 'HeatTop9Avg',\n       'SemiTop9Avg', 'TT1', 'TT2', 'TT3', 'TT4', 'TT5', 'TT6', 'TT7', 'TT8',\n       'TT9', 'T1_250', 'T2_250', 'T3_250', 'T4_250', 'T5_250', 'T6_250',\n       'T7_250', 'T8_250', 'T9_250', 'T1_500', 'T2_500', 'T3_500', 'T4_500',\n       'T5_500', 'T6_500', 'T7_500', 'T8_500', 'T9_500', 'T1_750', 'T2_750',\n       'T3_750', 'T4_750', 'T5_750', 'T6_750', 'T7_750', 'T8_750', 'T9_750',\n       'Total Time_y', 'Final Rank_y', 'TotalTime-1', 'Rank-1', 'TotalTime-2',\n       'Rank-2', 'TotalTime-3', 'Rank-3', 'TotalTime-4', 'Rank-4',\n       'TotalTime-5', 'Rank-5'],\n      dtype='object')\n"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data.csv\",sep=\";\",error_bad_lines=False)\n",
    "\n",
    "# Datum opschonen\n",
    "df = cleanColumns(df)\n",
    "#df = createRaceIndex(df)\n",
    "# Datum opsplitens in verschillende columns\n",
    "df = splitDateInColumns(df)\n",
    "#Create Teams\n",
    "df = createTeams(df)\n",
    "# Convert alle tijden naar seconden\n",
    "convertTimes(df)\n",
    "\n",
    "df = createIDs(df)\n",
    "\n",
    "#Make columns of categorial columns\n",
    "df = createCompetitionColumns(df)\n",
    "df = create_Reached_FinalA(df)\n",
    "df = create_Reached_Semi(df)\n",
    "df = create_DeltaTimes(df)\n",
    "\n",
    "\n",
    "\n",
    "df = create_count_FinalA_currentSeason(df)\n",
    "df = createPb_TimecurrentSeason(df)\n",
    "\n",
    "\n",
    "df =createAVGTIMETOP3(df)\n",
    "#getAverageTimeofRace(df)\n",
    "#df = dropColumns(df)\n",
    "df = createCompetitionTotal(df)\n",
    "df = getTotalAFinalsTeam(df)\n",
    "df = getTotalSemiFinalsTeam(df)\n",
    "df = createFastestHeatTimeInCompetition(df)\n",
    "df = createFastestSemiTimeInCompetition(df)\n",
    "df = createFastestFinalTimeInCompetition(df)\n",
    "#df = createConditions(df)\n",
    "df = createFastestTimeInCompetition(df)\n",
    "#df = createAvgTop3HeatTimeInCompetition(df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = createAvgTop3HeatTimeInCompetition(df)\n",
    "df = createAvgTop3SemiTimeInCompetition(df)\n",
    "\n",
    "df = createAvgTop9HeatTimeInCompetition(df)\n",
    "df = createAvgTop9SemiTimeInCompetition(df)\n",
    "df = rankeRaces(df)\n",
    "df = rankeRaces250(df)\n",
    "df = rankeRaces500(df)\n",
    "df = rankeRaces750(df)\n",
    "df = createMovingWindow(df)\n",
    "print(df.columns)\n",
    "\n",
    "df.to_csv(\"K2_MEN_DATASET.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "\"['Total Time', 'Final Rank'] not in index\"",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-6639ae73e631>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mRace_Dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Race_ID'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Competition_ID'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Competition Round_FINAL A\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Competition Round_FINAL B\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Competition Round_FINAL C\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Competition Round_HEAT\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Competition Round_SEMIFINAL\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Race_ID\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Data/Race_Dataset.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m Race_Team_Dataset = df[[\"Race_ID\",\"Team_ID\",\"Country\",\"Lane\",\"Final Rank\",\"split time 1\",\"split time 2\",\"split time 3\",\"Total Time\",\"TotalTime-1\",\"Rank-1\", \"TotalTime-2\",\"Rank-2\", \"TotalTime-3\",\"Rank-3\", \"TotalTime-4\", \"Rank-4\",\n\u001b[1;32m----> 3\u001b[1;33m        \"TotalTime-5\", \"Rank-5\"]].copy().drop_duplicates().set_index([\"Race_ID\",\"Team_ID\"]).to_csv(\"Data/Race_Team_Dataset.csv\")\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mCompetition_DataSet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Competition_ID'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Place'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Competiton Type_WORLDCHAMPIONSHIPS'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Competiton Type_WORLDCUP\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Year\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Competition_ID\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Data/Competition_Dataset.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mTeam_Dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Team_ID\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Country\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Person 1\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Person 2\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Team_ID\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Data/Team_Dataset.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2999\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3000\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3001\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3002\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3003\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[0;32m   1283\u001b[0m                 \u001b[1;31m# When setting, missing keys are not allowed, even with .loc:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1284\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"raise_missing\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mis_setter\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1285\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1286\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m         self._validate_read_indexer(\n\u001b[1;32m-> 1092\u001b[1;33m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1093\u001b[0m         )\n\u001b[0;32m   1094\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1183\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"loc\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1184\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1185\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{} not in index\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnot_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m             \u001b[1;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Total Time', 'Final Rank'] not in index\""
     ]
    }
   ],
   "source": [
    "Race_Dataset = df[['Race_ID','Competition_ID','Date',\"Competition Round_FINAL A\",\"Competition Round_FINAL B\",\"Competition Round_FINAL C\",\"Competition Round_HEAT\",\"Competition Round_SEMIFINAL\"]].copy().drop_duplicates().set_index(\"Race_ID\").to_csv(\"Data/Race_Dataset.csv\")\n",
    "Race_Team_Dataset = df[[\"Race_ID\",\"Team_ID\",\"Country\",\"Lane\",\"Final Rank\",\"split time 1\",\"split time 2\",\"split time 3\",\"Total Time\"]].copy().drop_duplicates().set_index([\"Race_ID\",\"Team_ID\"]).to_csv(\"Data/Race_Team_Dataset.csv\")\n",
    "Competition_DataSet = df[['Competition_ID','Place','Competiton Type_WORLDCHAMPIONSHIPS',\"Competiton Type_WORLDCUP\",\"Year\"]].copy().drop_duplicates().set_index(\"Competition_ID\").to_csv(\"Data/Competition_Dataset.csv\")\n",
    "Team_Dataset = df[[\"Team_ID\",\"Country\",\"Person 1\",\"Person 2\"]].copy().drop_duplicates().set_index(\"Team_ID\").to_csv(\"Data/Team_Dataset.csv\")\n",
    "\n",
    "\n",
    "Competetition_Analasys_Dataset = df[['Competition_ID','N1THeatCompetition','N1TSemiCompetition',\"N1TFinalACompetition\",\"N1TCompetition\",\"HeatTop3Avg\",\"SemiTop3Avg\",\"HeatTop9Avg\",\"SemiTop9Avg\"]].copy().drop_duplicates().set_index(\"Competition_ID\").to_csv(\"Data/Competition_Analasis_Dataset.csv\")\n",
    "Race_Analasis_Dataset = df[[\"Race_ID\",\"Condition\",'TT1', 'TT2', 'TT3', 'TT4', 'TT5', 'TT6', 'TT7', 'TT8',\n",
    "       'TT9', 'T1_250', 'T2_250', 'T3_250', 'T4_250', 'T5_250', 'T6_250',\n",
    "       'T7_250', 'T8_250', 'T9_250', 'T1_500', 'T2_500', 'T3_500', 'T4_500',\n",
    "       'T5_500', 'T6_500', 'T7_500', 'T8_500', 'T9_500', 'T1_750', 'T2_750',\n",
    "       'T3_750', 'T4_750', 'T5_750', 'T6_750', 'T7_750', 'T8_750', 'T9_750']].copy().set_index(\"Race_ID\").drop_duplicates().to_csv(\"Data/Race_Analasis_Dataset.csv\")\n",
    "df.to_csv(\"K2_MEN_DATASET.csv\")\n",
    "Team_Analasis_Dataset = df[[\"Team_ID\",\"Date\",\"FinalA_count_Season\",\"TotalSemiFinalsTogether\",\"BestSeasonTime\",\"TotalRacesTogether\"]].set_index([\"Team_ID\",\"Date\"]).to_csv(\"Data/Team_Analasis_Dataset.csv\")\n",
    "Team_Competition_Analasys_Dataset = df[[\"Team_ID\",\"Competition_ID\",\"Reached_FINAL_A\",\"Reached_SEMI\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}